numberofcampaigns <- html_nodes(html, ".odd .column-3, .even .column-3")
consumerrating <- html_nodes(html, ".odd .column-4, .even .column-4")
#Define separate variables
observationvalues<-html_text(observation)
marketingspendvalues<-html_text(marketingspend)
numberofcampaignsvalues<-html_text(numberofcampaigns)
consumerratingvalues<-html_text(consumerrating)
consumerratingvalues
#Structure data frame and remove heading
df = data.frame(observationvalues, marketingspendvalues, numberofcampaignsvalues, consumerratingvalues)
df2<-df[-1, ]
View(df2)
#Load HTML website:
html <- read_html("https://www.michaeljgrogan.com/rvest-web-scraping-using-r/")
#Include relevant HTML nodes using CSS generator:
marketingtable <- html_nodes(html, ".odd .column-4 , .odd .column-3 , .odd .column-2 , .odd .column-1, .even .column-4 , .even .column-3 , .even .column-2 , .even .column-1")
marketingtable
#Determine table length
length(marketingtable)
#Import table by html_text function
webtable <-html_text(marketingtable)
webtable
html
#Determine table length
length(marketingtable)
movie <- read_html("http://www.imdb.com/title/tt1490017/")
cast <- html_nodes(movie, "#titleCast span.itemprop")
html_text(cast)
html_name(cast)
html_attrs(cast)
html_attr(cast, "class")
webtable
marketingtable
webtable
#Structure separate variables according to node
observation <- html_nodes(html, ".odd .column-1, .even .column-1")
marketingspend <- html_nodes(html, ".odd .column-2, .even .column-2")
numberofcampaigns <- html_nodes(html, ".odd .column-3, .even .column-3")
consumerrating <- html_nodes(html, ".odd .column-4, .even .column-4")
#Define separate variables
observationvalues<-html_text(observation)
observationvalues
marketingspendvalues<-html_text(marketingspend)
marketingspendvalues
numberofcampaignsvalues<-html_text(numberofcampaigns)
consumerratingvalues<-html_text(consumerrating)
consumerratingvalues
#Structure data frame and remove heading
df = data.frame(observationvalues, marketingspendvalues, numberofcampaignsvalues, consumerratingvalues)
df2<-df[-1, ]
df2
View(df2)
#Define separate variables
observationvalues<-html_text(observation)
observationvalues
#Structure data frame and remove heading
df = data.frame(observationvalues, marketingspendvalues, numberofcampaignsvalues, consumerratingvalues)
df2<-df[,-1 ]
view(df2)
View(df2)
View(df3)
df3<-df[,-1 ]
View(df3)
df3<-df[-1, ]
View(df3)
df3<-df[1, ]
View(df3)
df2<-df[-1, ]
View(df2)
df3<-df[2, ]
View(df3)
df2<-df[1:6, ]
View(df2)
df2<-df[-1, ]
View(df2)
df2<-df[-2, ]
View(df2)
df2<-df[1:6, ]
View(df2)
#Load HTML website:
html <- read_html("https://24h.pchome.com.tw/prod/DYAJBS-A90097O9K")
#Include relevant HTML nodes using CSS generator:
marketingtable <- html_nodes(html, ".odd .column-4 , .odd .column-3 , .odd .column-2 , .odd .column-1, .even .column-4 , .even .column-3 , .even .column-2 , .even .column-1")
#Load HTML website:
html <- read_html("https://24h.pchome.com.tw/prod/DYAJBS-A90097O9K")
#Include relevant HTML nodes using CSS generator:
marketingtable <- html_nodes(html, ".odd .column-4 , .odd .column-3 , .odd .column-2 , .odd .column-1, .even .column-4 , .even .column-3 , .even .column-2 , .even .column-1")
marketingtable
#Determine table length
length(marketingtable)
#Import table by html_text function
webtable <-html_text(marketingtable)
webtable
#Load HTML website:
html <- read_html("https://www.apple.com/tw/iphone-xs/specs/")
#Include relevant HTML nodes using CSS generator:
marketingtable <- html_nodes(html, ".odd .column-4 , .odd .column-3 , .odd .column-2 , .odd .column-1, .even .column-4 , .even .column-3 , .even .column-2 , .even .column-1")
marketingtable
#Determine table length
length(marketingtable)
#Load HTML website:
html <- read_html("https://www.apple.com/tw/iphone-xs/specs/")
#Include relevant HTML nodes using CSS generator:
marketingtable <- html_nodes(html, ".odd .column-4 , .odd .column-3 , .odd .column-2 , .odd .column-1, .even .column-4 , .even .column-3 , .even .column-2 , .even .column-1")
marketingtable
#Load HTML website:
html <- read_html("https://www.cwb.gov.tw/V7/forecast/")
#Include relevant HTML nodes using CSS generator:
marketingtable <- html_nodes(html, ".odd .column-4 , .odd .column-3 , .odd .column-2 , .odd .column-1, .even .column-4 , .even .column-3 , .even .column-2 , .even .column-1")
marketingtable
#Determine table length
length(marketingtable)
#Load HTML website:
html <- read_html("https://www.cwb.gov.tw/V7/earthquake/")
#Include relevant HTML nodes using CSS generator:
marketingtable <- html_nodes(html, ".odd .column-4 , .odd .column-3 , .odd .column-2 , .odd .column-1, .even .column-4 , .even .column-3 , .even .column-2 , .even .column-1")
marketingtable
html
#Include relevant HTML nodes using CSS generator:
marketingtable <- html_nodes(html, ".odd .column-4 , .odd .column-3 , .odd .column-2 , .odd .column-1, .even .column-4 , .even .column-3 , .even .column-2 , .even .column-1")
html
#Load HTML website:
html <- read_html("http://scweb.cwb.gov.tw/Page.aspx?ItemId=22&eqdate=2018%2f08%2f29-11:51")
html
#Include relevant HTML nodes using CSS generator:
marketingtable <- html_nodes(html, ".odd .column-4 , .odd .column-3 , .odd .column-2 , .odd .column-1, .even .column-4 , .even .column-3 , .even .column-2 , .even .column-1")
marketingtable
#Include relevant HTML nodes using CSS generator:
marketingtable <- html_nodes(html")
#Determine table length
#Import table by html_text function
library(http)
library(rvest)
library(rvest)
html <- read_html(https://www.cwb.gov.tw/V7/earthquake/)
nods <- html_nodes(html, ".BoxTable02blue")
nods
html
nods <- html_nodes(html, "tr.BoxTable02blue")
html$node
html$doc
nods <- html_nodes(html, "BoxTable")
nod\
nods
nods <- html_nodes(html, ".BoxTable")
nods <- html_nodes(html, ".BoxTable")
nods
library(rvest)
html <- read_html("https://www.cwb.gov.tw/V7/earthquake/")
nods <- html_nodes(html, ".box2")
nods
nods <- html_nodes(html, ".最近地震")
nods
html <- read_html("https://www.cwb.gov.tw/V7/earthquake/")
nods <- html_nodes(html, ".earthshockinfo")
nods
https://www.michaeljgrogan.com/rvest-web-scraping-using-r/
#Load HTML website:
html <- read_html("https://www.michaeljgrogan.com/rvest-web-scraping-using-r/")
#Include relevant HTML nodes using CSS generator:
marketingtable <- html_nodes(html, ".odd .column-4 , .odd .column-3 , .odd .column-2 , .odd .column-1, .even .column-4 , .even .column-3 , .even .column-2 , .even .column-1")
nods <- html_nodes(html, ".BoxTable02")
library(rvest)
html <- read_html("https://www.cwb.gov.tw/V7/earthquake/")
nods <- html_nodes(html, ".BoxTable02")
nods
nods <- html_nodes(html, "table.BoxTable02")
nods
html
#Load HTML website:
html <- read_html("https://www.michaeljgrogan.com/rvest-web-scraping-using-r/")
#Include relevant HTML nodes using CSS generator:
marketingtable <- html_nodes(html, ".odd .column-4 , .odd .column-3 , .odd .column-2 , .odd .column-1, .even .column-4 , .even .column-3 , .even .column-2 , .even .column-1")
marketingtable
#Import table by html_text function
webtable <-html_text(marketingtable)
webtable
html <- read_html("https://www.cwb.gov.tw/V7/earthquake/")
html
library(rvest)
html <- read_html("https://www.cwb.gov.tw/V7/earthquake/")
html
nods <- html_nodes(html, ".BoxTable02")
nods
nods <- html_nodes(html, ".BoxTable02blue")
nods
nods <- html_nodes(html, ".planeleft02")
nods
nods <- html_nodes(html, ".BoxTable02blue")
nods
html <- read_html("https://www.imdb.com/search/title?groups=top_250&sort=user_rating")
html
nods <- html_nodes(html, ".lister-item mode-advanced")
nods
library(rvest)
html <- read_html("https://www.imdb.com/search/title?groups=top_250&sort=user_rating")
html
nods <- html_nodes(html, ".lister-item mode-advanced")
nods
nods <- html_nodes(html, ".lister-item-header .lister-item mode-advanced")
nods
nods <- html_nodes(html, ".lister-item-header.lister-item mode-advanced")
nods
nods <- html_nodes(html, ".lister-item-header.lister-item-content.lister-item mode-advanced")
nods
html
View(html)
nods <- html_nodes(html, ".lister-item-header")
nods
tete <- html_text(nods)
tete
tete <- html_text(nods)
df <- data.frame(tete)
View(df)
Movies <- html_text(nods)
df <- data.frame(Movies)
View(df)
library(rvest)
html <- read_html("https://www.imdb.com/search/title?groups=top_250&sort=user_rating")
nods <- html_nodes(html, ".lister-item-header")
Movies <- html_text(nods)
df <- data.frame(Movies)
View(df)
View(df)
html <- read_html("https://www.imdb.com/search/title?groups=top_250&sort=user_rating")
nods <- html_nodes(html, ".lister-item-header", ".inline-block ratings-imdb-rating")
Movies <- html_text(nods)
df <- data.frame(Movies)
View(df)
nods <- html_nodes(html, ".lister-item-header", ".ratings-bar")
html <- read_html("https://www.imdb.com/search/title?groups=top_250&sort=user_rating&page=1&ref_=adv_nxt")
nods <- html_nodes(html, ".lister-item-header", ".ratings-bar")
Movies <- html_text(nods)
df <- data.frame(Movies)
View(df)
library(rvest)
html <- read_html("https://kma.kkbox.com/charts/daily/song?terr=tw&lang=tc&cate=390")
nods <- html_nodes(html, ".charts-list-song")
songs <- html_text(nods)
df <- data.frame(songs)
View(df)
nods <- html_nodes(html, ".charts-list-desc")
songs <- html_text(nods)
df <- data.frame(songs)
View(df)
library(rvest)
html <- read_html("https://www.imdb.com/search/title?groups=top_250&sort=user_rating&page=1&ref_=adv_nxt")
nods <- html_nodes(html, ".lister-item-header")
Movies <- html_text(nods)
df <- data.frame(Movies)
View(df)
wine.data = read.csv("C:/Users/user/Documents/GitHub/Rlanguage/week_3/course/Book1.csv")
head(wine.data)
wine.data = read.csv(".Book1.csv")
wine.data = read.csv("./Book1.csv")
wine.data = read.csv("/Book1.csv")
getwd()
Book1.csv
wine.data = read.csv("Book1.csv")
library(ggmap)
library(ggplot2)
library(OpenStreetMap)
install.packages("OpenStreetMap")
library(ggplot2)
library(OpenStreetMap)
map <- openmap(
c(lat= 25.04, lon= 121.520),
c(lat= 25.025, lon= 121.535),
type="osm"
)
g <- autoplot(openproj(map))
# 顯示政大公企 location
g + geom_point(
data=NULL, x=121.52780, y=25.03049,
size=7, color="red", fill="pink",
shape=23
)
library(rvest)
lego_movie <- html("http://www.imdb.com/title/tt1490017/")
lego_movie %>%
html_node("strong span") %>%
html_text() %>%
as.numeric()
lego_movie %>%
html_node(" span") %>%
html_text() %>%
as.numeric()
lego_movie %>%
html_node("strong span") %>%
html_text() %>%
as.numeric()
lego_movie %>%
html_node("span a") %>%
html_text() %>%
as.numeric()
lego_movie %>%
html_node("a") %>%
html_text() %>%
as.numeric()
lego_movie %>%
html_node("h1") %>%
html_text() %>%
as.numeric()
lego_movie %>%
html_node("h1") %>%
html_text()
lego_movie %>%
html_node("a, h1") %>%
html_text()
lego_movie %>%
html_node("a, h1") %>%
html_text()
lego_movie %>%
html_node("a, h1") %>%
html_text() %>%
as.numeric()
lego_movie %>%
html_node("a") %>%
html_text() %>%
as.numeric()
lego_movie %>%
html_node("a") %>%
html_text()
lego_movie %>%
html_node("#titleyear") %>%
html_text()
lego_movie %>%
html_node("#titleYear") %>%
html_text()
lego_movie %>%
html_node("#titleYear, a") %>%
html_text()
lego_movie %>%
html_node("#titleYear a") %>%
html_text()
lego_movie %>%
html_node("h1") %>%
html_text()
lego_movie %>%
html_node("title_wrapper") %>%
html_text()
lego_movie %>%
html_node(".title_wrapper") %>%
html_text()
lego_movie %>%
html_node("#title_wrapper") %>%
html_text()
lego_movie %>%
html_node("h1") %>%
html_text()
lego_movie %>%
html_node("span") %>%
html_text()
lego_movie %>%
html_node("strong span") %>%
html_text()
lego_movie %>%
html_node("#titleCast .itemprop span") %>%
html_text()
library(rvest)
lego_movie <- html("http://www.imdb.com/title/tt1490017/")
lego_movie %>%
html_node("#titleCast .itemprop span") %>%
html_text()
setwd("C:/Users/user/Documents/GitHub/Rlanguage/week_4/hw")
lyrics = readLines("lyrics.txt")
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
docs <- Corpus(VectorSource(lyrics))
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("lennon", "mcCartney", "(", ")"))
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
View(d)
setwd("C:/Users/user/Documents/GitHub/Rlanguage/week_4/hw")
lyrics = readLines("lyrics.txt")
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
docs <- Corpus(VectorSource(lyrics))
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("lennon", "mcCartney", "(", ")"))
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
View(d)
d <- data.frame(word = names(v),freq=v)
View(d)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
setwd("C:/Users/user/Documents/GitHub/Rlanguage/week_4/hw")
lyrics = readLines("lyrics.txt")
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
docs <- Corpus(VectorSource(lyrics))
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("lennon", "mcCartney", "(", ")"))
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
View(d)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
setwd("C:/Users/user/Documents/GitHub/Rlanguage/week_4/hw")
lyrics = readLines("lyrics.txt")
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
docs <- Corpus(VectorSource(lyrics))
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("lennon", "mcCartney", "(", ")"))
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
View(d)
lyrics = readLines("lyrics1.txt")
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
docs <- Corpus(VectorSource(lyrics))
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("lennon", "mcCartney", "(", ")"))
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
dtm <- TermDocumentMatrix(docs)
# Text stemming
docs <- tm_map(docs, stemDocument)
m <- as.matrix(dtm)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
View(d)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
