library(tm)
library(tmcn)
library(Rwordseg)
library(jiebaR)
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
for (y in 91:107) {
nam <- paste("speech", y, sep = "")
assign(nam, readLines(paste(y, '.txt' , sep = "")))
}
cutter <- worker()
docs <- segment(speech100, cutter)
docs
cutter <- worker()
docs <- segment(speech100, cutter)
docs
for (y in 91:107) {
nam <- paste("speech", y, sep = "")
assign(nam, readLines(paste(y, '.txt' , sep = "")))
}
setwd("~/GitHub/Rlanguage/week_5/txt")
for (y in 91:107) {
nam <- paste("speech", y, sep = "")
assign(nam, readLines(paste(y, '.txt' , sep = "")))
}
setwd("~/GitHub/Rlanguage/week_4/hw/national park")
library(leaflet)
content <- read.csv("park.csv")
x <- paste("名稱： ", content$park,"<br>","成立時間： ", content$date)
m <- leaflet() %>%
addTiles() %>%  # Add default OpenStreetMap map tiles
addMarkers(lng=content$long, lat=content$lat,
popup=x)
m  # Print the map
content <- read.csv("park.csv")
x <- paste("名稱： ", content$park,"<br>","成立時間： ", content$date)
m <- leaflet() %>%
addTiles() %>%  # Add default OpenStreetMap map tiles
addMarkers(lng=content$long, lat=content$lat,
popup=x)
m  # Print the map
content <- read.csv("park.csv")
x <- paste("名稱： ", content$park,"<br>","成立時間： ", content$date)
m <- leaflet() %>%
addTiles() %>%  # Add default OpenStreetMap map tiles
addMarkers(lng=content$long, lat=content$lat,
popup=x)
m  # Print the map
knitr::opts_chunk$set(echo = TRUE)
library(leaflet)
content <- read.csv("park.csv")
x <- paste("名稱： ", content$park,"<br>","成立時間： ", content$date)
m <- leaflet() %>%
addTiles() %>%  # Add default OpenStreetMap map tiles
addMarkers(lng=content$long, lat=content$lat,
popup=x)
m  # Print the map
library(leaflet)
content <- read.csv("park.csv")
x <- paste("名稱： ", content$park,"<br>","成立時間： ", content$date)
m <- leaflet() %>%
addTiles() %>%  # Add default OpenStreetMap map tiles
addMarkers(lng=content$long, lat=content$lat,
popup=x)
m  # Print the map
library(tm)
library(tmcn)
library(Rwordseg)
library(jiebaR)
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
for (y in 91:107) {
nam <- paste("speech", y, sep = "")
assign(nam, readLines(paste(y, '.txt' , sep = "")))
nam <- iconv(data, "big5", "utf8")
}
setwd("~/GitHub/Rlanguage/week_5/hw/txt")
for (y in 91:107) {
nam <- paste("speech", y, sep = "")
assign(nam, readLines(paste(y, '.txt' , sep = "")))
nam <- iconv(data, "utf8", "big5")
}
for (y in 91:107) {
nam <- paste("speech", y, sep = "")
assign(nam, readLines(paste(y, '.txt' , sep = "")))
nam <- iconv(data, "utf8", "big5")
}
for (y in 91:107) {
nam <- paste("speech", y, sep = "")
assign(nam, readLines(paste(y, '.txt' , sep = ""), encoding = "big5"))
}
assign(nam, readLines(paste(y, '.txt' , sep = ""), encoding = "utf8"))
for (y in 91:107) {
nam <- paste("speech", y, sep = "")
assign(nam, readLines(paste(y, '.txt' , sep = ""), encoding = "utf8"))
}
for (y in 91:107) {
nam <- paste("speech", y, sep = "")
assign(nam, readLines(paste(y, '.txt' , sep = ""), encoding = "UTF-8"))
}
for (y in 91:107) {
nam <- paste("speech", y, sep = "")
assign(nam, readLines(paste(y, '.txt' , sep = ""), encoding = "UTF-8"))
}
for (y in 91:107) {
nam <- paste("speech", y, sep = "")
assign(nam, readLines(paste(y, '.txt' , sep = ""), encoding = "UTF-8"))
}
cutter <- worker()
docs <- segment(speech100, cutter)
docs <- filter_segment(docs,stopwordsCN())
docs<-gsub("[0-9]+?","",docs)###去除数字和英文
library(stringr)#加载stringr包
docs<-str_trim(docs)#去除空格
docs
docs <- segment(speech107, cutter)
docs <- filter_segment(docs,stopwordsCN())
docs<-gsub("[0-9]+?","",docs)###去除数字和英文
library(stringr)#加载stringr包
docs<-str_trim(docs)#去除空格
docs
cutter <- worker(stop_word = "停用詞.txt")
docs <- segment(speech107, cutter)
docs <- filter_segment(docs,stopwordsCN())
docs<-gsub("[0-9]+?","",docs)###去除数字和英文
library(stringr)#加载stringr包
docs<-str_trim(docs)#去除空格
docs
docs <- segment(speech100, cutter)
docs <- filter_segment(docs,stopwordsCN())
docs<-gsub("[0-9]+?","",docs)###去除数字和英文
library(stringr)#加载stringr包
docs<-str_trim(docs)#去除空格
docs
cutter <- worker(stop_word = "停用詞.txt")
docs<-str_trim(docs)#去除空格
docs <- segment(speech100, cutter)
docs <- filter_segment(docs,stopwordsCN())
docs<-gsub("[0-9]+?","",docs)###去除数字和英文
library(stringr)#加载stringr包
docs
cutter
cutter$bylines=TRUE
cutter <- worker(stop_word = "停用詞.txt")
docs <- segment(speech107, cutter)
docs <- filter_segment(docs,stopwordsCN())
docs<-gsub("[0-9]+?","",docs)###去除数字和英文
library(stringr)#加载stringr包
docs<-str_trim(docs)#去除空格
docs
cutter$bylines=TRUE
cutter <- worker(stop_word = "停用詞.txt")
docs <- segment(speech107, cutter)
docs <- filter_segment(docs,stopwordsCN())
library(stringr)#加载stringr包
docs<-str_trim(docs)#去除空格
docs
cutter$bylines=TRUE
cutter <- worker(stop_word = "停用詞.txt")
docs<-gsub("[0-9]+?","",docs)###去除数字和英文
docs <- segment(speech107, cutter)
docs <- filter_segment(docs,stopwordsCN())
library(stringr)#加载stringr包
docs<-str_trim(docs)#去除空格
docs
library(tm)
library(tmcn)
library(Rwordseg)
library(jiebaR)
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
cutter <- worker(stop_word = "停用詞.txt")
for (y in 91:107) {
nam <- paste("speech", y, sep = "")
assign(nam, readLines(paste(y, '.txt' , sep = ""), encoding = "UTF-8"))
}
docs <- segment(speech107, cutter)
docs <- filter_segment(docs,stopwordsCN())
library(tm)
library(tmcn)
library(Rwordseg)
library(jiebaR)
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
cutter <- worker(stop_word = "停用詞.txt")
for (y in 91:107) {
nam <- paste("speech", y, sep = "")
assign(nam, readLines(paste(y, '.txt' , sep = ""), encoding = "UTF-8"))
}
docs <- segment(speech107, cutter)
library(stringr)#加载stringr包
docs<-str_trim(docs)#去除空格
docs
docs <- filter_segment(docs,stopwordsCN())
library(stringr)#加载stringr包
docs<-str_trim(docs)#去除空格
docs
library(tm)
library(tmcn)
library(Rwordseg)
library("SnowballC")
library(jiebaR)
library("wordcloud")
library("RColorBrewer")
cutter <- worker(stop_word = "停用詞.txt")
for (y in 91:107) {
nam <- paste("speech", y, sep = "")
assign(nam, readLines(paste(y, '.txt' , sep = ""), encoding = "UTF-8"))
}
docs <- segment(speech107, cutter)
library(stringr)#加载stringr包
docs<-str_trim(docs)#去除空格
docs
docs <- filter_segment(docs,stopwordsCN())
library(stringr)#加载stringr包
docs<-str_trim(docs)#去除空格
docs
docs
library(tm)
library(tmcn)
library(Rwordseg)
library(jiebaR)
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
cutter <- worker(stop_word = "停用詞.txt")
for (y in 91:107) {
nam <- paste("speech", y, sep = "")
assign(nam, readLines(paste(y, '.txt' , sep = ""), encoding = "UTF-8"))
}
docs <- segment(speech107, cutter)
library(stringr)#加载stringr包
docs<-str_trim(docs)#去除空格
docs
sort(table(cutter[docs]),decreasing = T)
library(plyr)
tableWord <- count(docs)
tableWord
wordcloud(tableWord[,1],tableWord[,2],random.order=F,col= rainbow(length(docs)))
tableWord$freq==3
tableWord<- tableWord$freq==3
tableWord
tableWord$x
wordcloud(tableWord[,1],tableWord[,2],random.order=T,col= rainbow(length(docs)))
wordcloud(tableWord[,1],tableWord[,2],random.order=T,col= rainbow(length(docs)))
wordcloud(tableWord[,1],tableWord[,2],random.order=F,col= rainbow(length(docs)))
tableWord <- count(docs)
tableWord<- tableWord$freq==3
wordcloud(tableWord[,1],tableWord[,2],random.order=F,col= rainbow(length(docs)))
sort(table(cutter[docs]),decreasing = T)
library(plyr)
tableWord <- count(docs)
tableWord<- tableWord$freq==3
wordcloud(tableWord[,1],tableWord[,2],random.order=F,col= rainbow(length(docs)))
library(tm)
library(tmcn)
library(Rwordseg)
library(jiebaR)
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
cutter <- worker(stop_word = "停用詞.txt")
for (y in 91:107) {
nam <- paste("speech", y, sep = "")
assign(nam, readLines(paste(y, '.txt' , sep = ""), encoding = "UTF-8"))
}
docs <- segment(speech107, cutter)
library(stringr)#加载stringr包
docs<-str_trim(docs)#去除空格
sort(table(cutter[docs]),decreasing = T)
library(plyr)
tableWord <- count(docs)
tableWord<- tableWord$freq==3
wordcloud(tableWord[,1],tableWord[,2],random.order=F,col= rainbow(length(docs)))
library(tm)
library(tmcn)
library(Rwordseg)
library(jiebaR)
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
cutter <- worker(stop_word = "停用詞.txt")
for (y in 91:107) {
nam <- paste("speech", y, sep = "")
assign(nam, readLines(paste(y, '.txt' , sep = ""), encoding = "UTF-8"))
}
docs <- segment(speech107, cutter)
library(stringr)#加载stringr包
docs<-str_trim(docs)#去除空格
sort(table(cutter[docs]),decreasing = T)
library(plyr)
tableWord <- count(docs)
wordcloud(tableWord[,1],tableWord[,2],random.order=F,col= rainbow(length(docs)))
wordcloud(tableWord[,1],tableWord[,2],random.order=F,col= rainbow))
wordcloud(tableWord[,1],tableWord[,2],random.order=F,col= rainbow)
wordcloud(tableWord[,1],tableWord[,2],random.order=T,col= rainbow(length(docs)))
wordcloud(tableWord[,1],tableWord[,2],random.order=F,col= rainbow(length(docs)))
wordcloud(tableWord[,1],tableWord[,2],random.order=F)
wordcloud(tableWord[,1],tableWord[,2],random.order=F,random.color = T)
wordcloud(tableWord[,1],tableWord[,2],random.order=F,colors= rainbow(length(docs)))
wordcloud(tableWord[,1],tableWord[,3],random.order=F,colors= rainbow(length(docs)))
wordcloud(tableWord[,1],tableWord[,2],random.order=F,colors= rainbow(length(docs)))
tableWord <- count(docs)
tableWord
wordcloud(tableWord[,1],tableWord[,2],random.order=F,rot.per = .1,colors= rainbow(length(docs)))
wordcloud(tableWord[,1],tableWord[,2],random.order=F,rot.per = .2,colors= rainbow(length(docs)))
wordcloud(tableWord[,1],tableWord[,2],random.order=F,rot.per = .3,colors= rainbow(length(docs)))
wordcloud(tableWord[,1],tableWord[,2],random.order=F,rot.per = .1,colors= rainbow(length(docs)))
wordcloud(tableWord[,1],tableWord[,2],random.order=F,rot.per = 0,colors= rainbow(length(docs)))
wordcloud(tableWord[,1],tableWord[,2],random.order=F,rot.per = T,colors= rainbow(length(docs)))
wordcloud(tableWord[,1],tableWord[,2],random.order=F,rot.per = .5,colors= rainbow(length(docs)))
wordcloud(tableWord[,1],tableWord[,2],random.order=F,rot.per = F,colors= rainbow(length(docs)))
class(tableWord)
sort(table(cutter[docs]),decreasing = T)
class(docs)
aaa<-sort(table(cutter[docs]),decreasing = T)
class(aaa)
aaa$x
aaa<-sort((cutter[docs]),decreasing = T)
aaa
docs <- cutter(speech107) # initialized engines for words segmentation
docs <- cutter[speech107] # initialized engines for words segmentation
docs
getOption()
getOption("max.print")
getOption(max.print)
getOption("max.print"=10000)
getOption("max.print")<-10000
option(max.print=10000)
options(max.print=10000)
docs
library(tm)
library(tmcn)
library(Rwordseg)
library(jiebaR)
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
cutter <- worker(stop_word = "停用詞.txt") #initialize jiebaR workers
for (y in 91:107) {
nam <- paste("speech", y, sep = "")
assign(nam, readLines(paste(y, '.txt' , sep = ""), encoding = "UTF-8"))
}
docs <- cutter[speech107] # initialized engines for words segmentation
library(stringr)#加载stringr包
docs<-str_trim(docs)#去除空格
docs
library(plyr)
tableWord <- count(docs) #Equivalent to as.data.frame(table(x))
wordcloud(tableWord[,1],tableWord[,2],random.order=F,rot.per = F,colors= rainbow(length(docs)))
sort(table(cutter[docs]),decreasing = T)
cutter <- worker(stop_word = "停用詞.txt") #initialize jiebaR workers
docs <- cutter[speech107] # initialized engines for words segmentation
library(stringr)#加载stringr包
docs<-str_trim(docs)#去除空格
docs
options(max.print=10000)
sort(table(cutter[docs]),decreasing = T)
wordcloud(tableWord[,1],tableWord[,2],min.freq=3,random.order=F,rot.per = F,colors= rainbow(length(docs)))
wordcloud(tableWord[,1],tableWord[,2],min.freq=5,random.order=F,rot.per = F,colors= rainbow(length(docs)))
wordcloud(tableWord[,1],tableWord[,2],min.freq=1,random.order=F,rot.per = F,colors= rainbow(length(docs)))
wordcloud(tableWord[,1],tableWord[,2],min.freq=2,random.order=F,rot.per = F,colors= rainbow(length(docs)))
wordcloud(tableWord[,1],tableWord[,2],min.freq=2,random.order=F,rot.per = F,colors= rainbow(length(docs)))
wordcloud(tableWord[,1],tableWord[,2],min.freq=3,random.order=F,rot.per = F,colors= rainbow(length(docs)))
sort(table(docs),decreasing = T)
table(docs)
table(docs)
tb$freq
tb<-table(docs)
tb$freq
tableWord
class(tableWord)
class(tb)
str(tableWord)
library(jiebaR)
library(stringr)#加载stringr包
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
cutter <- worker(stop_word = "停用詞.txt") #initialize jiebaR workers
for (y in 91:107) {
nam <- paste("speech", y, sep = "")
assign(nam, readLines(paste(y, '.txt' , sep = ""), encoding = "UTF-8"))
}
docs <- cutter[speech107]
docs<-str_trim(docs)#去除空格
docs
sort(table(docs),decreasing = T)
library(plyr)
tableWord <- count(docs) #Equivalent to as.data.frame(table(x))
str(tableWord)
wordcloud(tableWord[,1],tableWord[,2],min.freq=3,random.order=F,rot.per = F,colors= rainbow(length(docs)))
setwd("~/GitHub/Rlanguage/week_5/hw/txt")
setwd("~/GitHub/Rlanguage/week_5/hw/txt")
knitr::opts_chunk$set(echo = TRUE)
#initialize jiebaR workers
cutter <- worker(stop_word = "停用詞.txt")
library(jiebaR)
library(stringr)
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
cutter <- worker(stop_word = "停用詞.txt") #initialize jiebaR workers
# load speeches
for (y in 91:107) {
nam <- paste("speech", y, sep = "")
assign(nam, readLines(paste(y, '.txt' , sep = ""), encoding = "UTF-8"))
}
library(jiebaR)
library(stringr)
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
for (y in 91:107) {
nam <- paste("speech", y, sep = "")
assign(nam, readLines(paste(y, '.txt' , sep = ""), encoding = "UTF-8"))
}
docs <- cutter[speech107]
docs<-str_trim(docs)#去除空格
docs
cutter <- worker(stop_word = "停用詞.txt") #initialize jiebaR workers
library(jiebaR)
library(stringr)
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
cutter <- worker(stop_word = "停用詞.txt") #initialize jiebaR workers
for (y in 91:107) {
nam <- paste("speech", y, sep = "")
assign(nam, readLines(paste(y, '.txt' , sep = ""), encoding = "UTF-8"))
}
docs <- cutter[speech107]
docs
library(jiebaR)
library(stringr)
library("SnowballC")
library("wordcloud")
cutter <- worker(stop_word = "停用詞.txt") #initialize jiebaR workers
for (y in 91:107) {
nam <- paste("speech", y, sep = "")
assign(nam, readLines(paste(y, '.txt' , sep = ""), encoding = "UTF-8"))
}
docs <- cutter[speech107]
docs
sort(table(docs),decreasing = T)
tb<-table(docs)
tableWord <- as.data.frame(docs) #Equivalent to as.data.frame(table(x))
str(tableWord)
wordcloud(tableWord[,1],tableWord[,2],min.freq=3,random.order=F,rot.per = F,colors= rainbow(length(docs)))
library(plyr)
docs<-str_trim(docs)#去除空格
library("RColorBrewer")
library(jiebaR)
library(stringr)
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
cutter <- worker(stop_word = "停用詞.txt") #initialize jiebaR workers
for (y in 91:107) {
nam <- paste("speech", y, sep = "")
assign(nam, readLines(paste(y, '.txt' , sep = ""), encoding = "UTF-8"))
}
docs <- cutter[speech107]
docs<-str_trim(docs)#去除空格
docs
sort(table(docs),decreasing = T)
tb<-table(docs)
library(plyr)
tableWord <- as.data.frame(docs) #Equivalent to as.data.frame(table(x))
str(tableWord)
wordcloud(tableWord[,1],tableWord[,2],min.freq=3,random.order=F,rot.per = F,colors= rainbow(length(docs)))
tableWord <- count(docs) #Equivalent to as.data.frame(table(x))
str(tableWord)
wordcloud(tableWord[,1],tableWord[,2],min.freq=3,random.order=F,rot.per = F,colors= rainbow(length(docs)))
tableWord <- as.data.frame(docs) #Equivalent to as.data.frame(table(x))
str(tableWord)
tableWord <- as.data.frame(table(docs)) #Equivalent to as.data.frame(table(x))
str(tableWord)
wordcloud(tableWord[,1],tableWord[,2],min.freq=3,random.order=F,rot.per = F,colors= rainbow(length(docs)))
wordcloud(tableWord[,1],tableWord[,2],min.freq=3,random.order=F,rot.per = F,colors= rainbow(length(docs)))
library(plyr)
tableWord <- as.data.frame(table(docs)) #Equivalent to as.data.frame(table(x))
str(tableWord)
wordcloud(tableWord[,1],tableWord[,2],min.freq=3,random.order=F,rot.per = F,colors= rainbow(length(docs)))
count
tableWord <- count(docs) #Equivalent to as.data.frame(table(x))
str(tableWord)
wordcloud(tableWord[,1],tableWord[,2],min.freq=3,random.order=F,rot.per = F,colors= rainbow(length(docs)))
tableWord <- count(docs) #Equivalent to as.data.frame(table(x))
str(tableWord)
wordcloud(tableWord[,1],tableWord[,2],min.freq=3,random.order=F,rot.per = F,colors= rainbow(length(docs)))
